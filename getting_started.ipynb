{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with COD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cloud_optimized_dicom.cod_object import CODObject\n",
    "from cloud_optimized_dicom.instance import Instance\n",
    "from cloud_optimized_dicom.utils import delete_uploaded_blobs\n",
    "from cloud_optimized_dicom.dicomweb import handle_request\n",
    "from google.cloud import storage\n",
    "import pydicom\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "assert hasattr(CODObject, \"get_instances\")\n",
    "\n",
    "client = storage.Client()\n",
    "\n",
    "datastore_path = \"gs://cod-test-bucket/test-datastore/v1.0/dicomweb\"\n",
    "deid_datastore_path = \"gs://cod-test-bucket/test-datastore-deid/v1.0/dicomweb\"\n",
    "\n",
    "test_data_dir = os.path.join(os.path.abspath(\"\"), \"cloud_optimized_dicom\", \"tests\", \"test_data\")\n",
    "assert os.path.isdir(test_data_dir)\n",
    "instance_a_uri = os.path.join(test_data_dir, \"series\", \"1.2.826.0.1.3680043.8.498.22997958494980951977704130269567444795.dcm\")\n",
    "instance_b_uri = os.path.join(test_data_dir, \"series\", \"1.2.826.0.1.3680043.8.498.28109707839310833322020505651875585013.dcm\")\n",
    "instance_c_uri = os.path.join(test_data_dir, \"series\", \"1.2.826.0.1.3680043.8.498.33347096455284694650050230139909637623.dcm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a COD Object from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure the datastore is empty before we start\n",
    "delete_uploaded_blobs(client=client, uris_to_delete=[datastore_path])\n",
    "\n",
    "instance_a = Instance(instance_a_uri)\n",
    "with CODObject(datastore_path=datastore_path, \n",
    "               client=client, \n",
    "               study_uid=instance_a.study_uid(), \n",
    "               series_uid=instance_a.series_uid(), \n",
    "               lock=True) as cod_obj:\n",
    "    cod_obj.append(instances=[instance_a])\n",
    "    cod_obj.sync()\n",
    "    assert len(cod_obj.get_metadata().instances) == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append to an existing COD Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_b = Instance(instance_b_uri)\n",
    "with CODObject(datastore_path=datastore_path, \n",
    "               client=client, \n",
    "               study_uid=instance_a.study_uid(), \n",
    "               series_uid=instance_a.series_uid(), \n",
    "               lock=True) as cod_obj:\n",
    "    cod_obj.append(instances=[instance_b])\n",
    "    cod_obj.sync()\n",
    "    # there should be 2 instances in the COD: A and B!\n",
    "    assert len(cod_obj.get_metadata().instances) == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open a specific instance in pydicom from COD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All instances UIDs in the series:  dict_keys(['1.2.826.0.1.3680043.8.498.25686983467200677455391333207792083612', '1.2.826.0.1.3680043.8.498.51559928123146446551440195325528927455'])\n",
      "Instance with UID 1.2.826.0.1.3680043.8.498.25686983467200677455391333207792083612 has SOPInstanceUID: 1.2.826.0.1.3680043.8.498.25686983467200677455391333207792083612\n",
      "Instance with index 1 has SOPInstanceUID: 1.2.826.0.1.3680043.8.498.51559928123146446551440195325528927455\n",
      "Instance object Instance(uri=/var/folders/c2/zbssspdd0d95m1kv1c2z1tf80000gn/T/tmp3d4tqvsj_1.2.826.0.1.3680043.8.498.53683297893086086544068651189614355506/1.2.826.0.1.3680043.8.498.53683297893086086544068651189614355506.tar://instances/1.2.826.0.1.3680043.8.498.51559928123146446551440195325528927455.dcm, hashed_uids=False, instance_uid=1.2.826.0.1.3680043.8.498.51559928123146446551440195325528927455, series_uid=1.2.826.0.1.3680043.8.498.53683297893086086544068651189614355506, study_uid=1.2.826.0.1.3680043.8.498.77805869330689203045629680212005263354, dependencies=[]) has SOPInstanceUID: 1.2.826.0.1.3680043.8.498.51559928123146446551440195325528927455\n"
     ]
    }
   ],
   "source": [
    "cod_obj = CODObject(datastore_path=datastore_path, \n",
    "                    client=client, \n",
    "                    study_uid=instance_a.study_uid(), \n",
    "                    series_uid=instance_a.series_uid(), \n",
    "                    lock=False)\n",
    "# get a dict of all instances in the series\n",
    "print(\"All instances UIDs in the series: \", cod_obj.get_instances(dirty=True).keys())\n",
    "# get a specific instance by uid\n",
    "instance_from_uid = cod_obj.get_instance(instance_a.instance_uid(), dirty=True)\n",
    "# get a specific instance by index (instances as an ordered list by InstanceNumber, SliceLocation, etc.)\n",
    "second_instance = cod_obj.get_instance_by_index(1, dirty=True)\n",
    "# open an instance by uid\n",
    "with cod_obj.open_instance(instance_b.instance_uid(), dirty=True) as f:\n",
    "    ds = pydicom.dcmread(f)\n",
    "    print(f\"Instance with UID {instance_b.instance_uid()} has SOPInstanceUID: {ds.SOPInstanceUID}\")\n",
    "# open an instance by index\n",
    "with cod_obj.open_instance(1, dirty=True) as f:\n",
    "    ds = pydicom.dcmread(f)\n",
    "    print(f\"Instance with index {1} has SOPInstanceUID: {ds.SOPInstanceUID}\")\n",
    "# open an instance by object\n",
    "with cod_obj.open_instance(second_instance, dirty=True) as f:\n",
    "    ds = pydicom.dcmread(f)\n",
    "    print(f\"Instance object {second_instance} has SOPInstanceUID: {ds.SOPInstanceUID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove an instance from COD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove is really just syntactic sugar for truncate_everything_except(stuff_you_didnt_remove)\n",
    "\n",
    "with CODObject(datastore_path=datastore_path, \n",
    "               client=client, \n",
    "               study_uid=instance_a.study_uid(), \n",
    "               series_uid=instance_a.series_uid(), \n",
    "               lock=False) as cod_obj:\n",
    "    # there should be 2 instances in the COD\n",
    "    assert len(cod_obj.get_metadata(dirty=True).instances) == 2\n",
    "    instance = cod_obj.get_metadata(dirty=True).instances[instance_a.instance_uid()]\n",
    "    cod_obj.remove(instances=[instance], dirty=True)\n",
    "    # now that we removed instance a, there should be 1 instance in the COD\n",
    "    assert len(cod_obj.get_metadata(dirty=True).instances) == 1\n",
    "    # NOTE: we did not call cod_obj.sync() here, so this removal is only local and is not reflected in the datastore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Truncate (or \"destructive append\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_c = Instance(instance_c_uri)\n",
    "with CODObject(datastore_path=datastore_path, \n",
    "               client=client, \n",
    "               study_uid=instance_a.study_uid(), \n",
    "               series_uid=instance_a.series_uid(), \n",
    "               lock=False) as cod_obj:\n",
    "    # right now, COD contains instance A and instance B\n",
    "    assert list(cod_obj.get_metadata(dirty=True).instances.keys()) == [instance_a.instance_uid(), instance_b.instance_uid()]\n",
    "    cod_obj.truncate(instances=[instance_a, instance_c], dirty=True)\n",
    "    # after truncation, COD contains instances A and C, but not B\n",
    "    assert list(cod_obj.get_metadata(dirty=True).instances.keys()) == [instance_a.instance_uid(), instance_c.instance_uid()]\n",
    "    # NOTE: we did not call cod_obj.sync() here, so this truncation is only local and is not reflected in the datastore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a thumbnail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thumbnail generated at:  /var/folders/c2/zbssspdd0d95m1kv1c2z1tf80000gn/T/tmp2i4t1gce_1.2.826.0.1.3680043.8.498.53683297893086086544068651189614355506/thumbnail.mp4\n"
     ]
    }
   ],
   "source": [
    "# change to cod_obj.get_thumbnail(generate_if_missing=True) -> uint numpy array... fetch and return thumbnail if it exists, generate it if it doesn't (or fail if generate_if_missing=False)\n",
    "\n",
    "# instance.get_thumbnail() -> cod_obj.get_thumbnail()[slice_for_instance]\n",
    "\n",
    "# cod_obj.get_instance_from_thumbnail_index(thumbnail_index) -> Instance\n",
    "\n",
    "with CODObject(datastore_path=datastore_path, \n",
    "               client=client, \n",
    "               study_uid=instance_a.study_uid(), \n",
    "               series_uid=instance_a.series_uid(), \n",
    "               lock=False) as cod_obj:\n",
    "    thumbnail_local_path = cod_obj.generate_thumbnail(dirty=True)\n",
    "    print(\"Thumbnail generated at: \", thumbnail_local_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add custom metadata tags to COD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cod_obj.remove_custom_tag(tag_name)\n",
    "\n",
    "# rename custom tag to metadata field: cod_obj.add_metadata_field(field_name, field_value)\n",
    "\n",
    "# clearer nomenclature\n",
    "\n",
    "with CODObject(datastore_path=datastore_path, \n",
    "               client=client, \n",
    "               study_uid=instance_a.study_uid(), \n",
    "               series_uid=instance_a.series_uid(), \n",
    "               lock=False) as cod_obj:\n",
    "    cod_obj.add_custom_tag(tag_name=\"my_tag\", tag_value=\"my_value\", dirty=True)\n",
    "    assert cod_obj.get_custom_tag(tag_name=\"my_tag\", dirty=True) == \"my_value\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify and Save an instance in COD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# right now when you open a cod object you are opening it in read mode\n",
    "# but if we did want to support write mode, then the backend changes a lot\n",
    "# ex: rather than pulling a tar, you would pull the tar and actually extract it so you have the files\n",
    "# then you would be able to modify the files directly\n",
    "# you would basically not have metadata (the metadata.json would be invalid because you're changing stuff)\n",
    "# would be way easier to just have an truncate() call under the hood when the write is over\n",
    "\n",
    "# simplified: metadata/get_metadata()/get_thumbnail() inherently slow due to having to generate them on the fly\n",
    "# you can't write a cod file, but you can write on instances\n",
    "\n",
    "# cod_obj.get_instance(instance_uid).open(\"w\") -> extract the tar, modify the instance, then truncate()\n",
    "\n",
    "# more advanced and efficient would be write mode on the cod object itself, so we're not extracting/truncating for every instance\n",
    "\n",
    "with CODObject(datastore_path=datastore_path, \n",
    "               client=client, \n",
    "               study_uid=instance_a.study_uid(), \n",
    "               series_uid=instance_a.series_uid(), \n",
    "               lock=False) as cod_obj:\n",
    "    # fetch the tar from GCS\n",
    "    cod_obj.pull_tar(dirty=True)\n",
    "    instance = cod_obj.get_metadata(dirty=True).instances[instance_a.instance_uid()]\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".dcm\") as temp_file:\n",
    "        # save a modified version of the instance to a temp file\n",
    "        with instance.open() as f:\n",
    "            ds = pydicom.dcmread(f)\n",
    "            assert ds.PatientName == \"GRDNB4C659BSD9NZ\"\n",
    "            ds.PatientName = \"John Doe\"\n",
    "            ds.save_as(temp_file.name)\n",
    "        # remove the original instance from the COD\n",
    "        cod_obj.remove(instances=[instance], dirty=True)\n",
    "        # append the modified instance to the COD\n",
    "        cod_obj.append(instances=[Instance(temp_file.name)], dirty=True)\n",
    "        # there should be 2 instances in the COD: the modified instance A, and instance B\n",
    "        assert len(cod_obj.get_metadata(dirty=True).instances) == 2\n",
    "    # when we open the instance, we should see the changes\n",
    "    modified_instance = cod_obj.get_metadata(dirty=True).instances[instance_a.instance_uid()]\n",
    "    with modified_instance.open() as f:\n",
    "        ds = pydicom.dcmread(f)\n",
    "        assert ds.PatientName == \"John Doe\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interact with COD datastore via dicomweb requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# series_metadata = CODObject.dicomweb(GET {datastore_path}/studies/{study_uid}/series/{series_uid}/metadata, client)\n",
    "\n",
    "# lose the GET... later, if supported, can add options for POST, PUT, etc.\n",
    "\n",
    "# get study-level metadata (returns a dict of study level tags)\n",
    "study_metadata = handle_request(f\"GET {datastore_path}/studies/{instance_a.study_uid()}/metadata\", client)\n",
    "assert study_metadata[\"00100020\"][\"Value\"][0] == \"GRDNB4C659BSD9NZ\"\n",
    "\n",
    "# get series-level metadata (returns list of instance level tag dicts)\n",
    "series_metadata = handle_request(f\"GET {datastore_path}/studies/{instance_a.study_uid()}/series/{instance_a.series_uid()}/metadata\", client)\n",
    "assert series_metadata[0][\"00080018\"][\"Value\"][0] == instance_a.instance_uid()\n",
    "\n",
    "# get instance-level metadata (returns instance level tag dict)\n",
    "instance_metadata = handle_request(f\"GET {datastore_path}/studies/{instance_a.study_uid()}/series/{instance_a.series_uid()}/instances/{instance_a.instance_uid()}/metadata\", client)\n",
    "assert instance_metadata[\"00080018\"][\"Value\"][0] == instance_a.instance_uid()\n",
    "\n",
    "# get a frame from an instance (expect a list of raw bytes of the frame(s))\n",
    "frame = handle_request(f\"GET {datastore_path}/studies/{instance_a.study_uid()}/series/{instance_a.series_uid()}/instances/{instance_a.instance_uid()}/frames/1\", client)\n",
    "assert isinstance(frame, list)\n",
    "assert len(frame) == 1\n",
    "assert isinstance(frame[0], bytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a de-identified COD from an existing COD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/var/folders/c2/zbssspdd0d95m1kv1c2z1tf80000gn/T/tmpu4ust4fw_1.2.826.0.1.3680043.8.498.53683297893086086544068651189614355506/1.2.826.0.1.3680043.8.498.53683297893086086544068651189614355506.tar://instances/1.2.826.0.1.3680043.8.498.51559928123146446551440195325528927455.dcm'\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cal/work/cloud_optimized_dicom/cloud_optimized_dicom/append.py\", line 439, in _create_or_append_tar\n",
      "    instance.append_to_series_tar(tar)\n",
      "  File \"/Users/cal/work/cloud_optimized_dicom/cloud_optimized_dicom/instance.py\", line 311, in append_to_series_tar\n",
      "    tar.add(self.dicom_uri, arcname=f\"/instances/{uid_for_uri}.dcm\")\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/tarfile.py\", line 2194, in add\n",
      "    tarinfo = self.gettarinfo(name, arcname)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/tarfile.py\", line 2067, in gettarinfo\n",
      "    statres = os.lstat(name)\n",
      "              ^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/var/folders/c2/zbssspdd0d95m1kv1c2z1tf80000gn/T/tmpu4ust4fw_1.2.826.0.1.3680043.8.498.53683297893086086544068651189614355506/1.2.826.0.1.3680043.8.498.53683297893086086544068651189614355506.tar://instances/1.2.826.0.1.3680043.8.498.51559928123146446551440195325528927455.dcm'\n",
      "[Errno 2] No such file or directory: '/var/folders/c2/zbssspdd0d95m1kv1c2z1tf80000gn/T/tmpu4ust4fw_1.2.826.0.1.3680043.8.498.53683297893086086544068651189614355506/1.2.826.0.1.3680043.8.498.53683297893086086544068651189614355506.tar://instances/1.2.826.0.1.3680043.8.498.25686983467200677455391333207792083612.dcm'\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cal/work/cloud_optimized_dicom/cloud_optimized_dicom/append.py\", line 439, in _create_or_append_tar\n",
      "    instance.append_to_series_tar(tar)\n",
      "  File \"/Users/cal/work/cloud_optimized_dicom/cloud_optimized_dicom/instance.py\", line 311, in append_to_series_tar\n",
      "    tar.add(self.dicom_uri, arcname=f\"/instances/{uid_for_uri}.dcm\")\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/tarfile.py\", line 2194, in add\n",
      "    tarinfo = self.gettarinfo(name, arcname)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/tarfile.py\", line 2067, in gettarinfo\n",
      "    statres = os.lstat(name)\n",
      "              ^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/var/folders/c2/zbssspdd0d95m1kv1c2z1tf80000gn/T/tmpu4ust4fw_1.2.826.0.1.3680043.8.498.53683297893086086544068651189614355506/1.2.826.0.1.3680043.8.498.53683297893086086544068651189614355506.tar://instances/1.2.826.0.1.3680043.8.498.25686983467200677455391333207792083612.dcm'\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "GRADIENT_STATE_LOGS:FAILED_TO_TAR_ALL_INSTANCES:/var/folders/c2/zbssspdd0d95m1kv1c2z1tf80000gn/T/tmpu4ust4fw_1.2.826.0.1.3680043.8.498.53683297893086086544068651189614355506/1.2.826.0.1.3680043.8.498.53683297893086086544068651189614355506.tar://instances/1.2.826.0.1.3680043.8.498.51559928123146446551440195325528927455.dcm\n/var/folders/c2/zbssspdd0d95m1kv1c2z1tf80000gn/T/tmpu4ust4fw_1.2.826.0.1.3680043.8.498.53683297893086086544068651189614355506/1.2.826.0.1.3680043.8.498.53683297893086086544068651189614355506.tar://instances/1.2.826.0.1.3680043.8.498.25686983467200677455391333207792083612.dcm",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[64]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     23\u001b[39m     i.uid_hash_func = example_hash_function\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m CODObject(datastore_path=deid_datastore_path, \n\u001b[32m     25\u001b[39m                client=client, \n\u001b[32m     26\u001b[39m                study_uid=hashed_study_uid, \n\u001b[32m     27\u001b[39m                series_uid=hashed_series_uid,\n\u001b[32m     28\u001b[39m                hashed_uids=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     29\u001b[39m                lock=\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m deid_cod:\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     \u001b[43mdeid_cod\u001b[49m\u001b[43m.\u001b[49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstances\u001b[49m\u001b[43m=\u001b[49m\u001b[43minstances\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirty\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/cloud_optimized_dicom/cloud_optimized_dicom/utils.py:166\u001b[39m, in \u001b[36mpublic_method.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.lock:\n\u001b[32m    163\u001b[39m     logger.warning(\n\u001b[32m    164\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPerforming dirty operation \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m on locked CODObject: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    165\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/cloud_optimized_dicom/cloud_optimized_dicom/cod_object.py:230\u001b[39m, in \u001b[36mCODObject.append\u001b[39m\u001b[34m(self, instances, treat_metadata_diffs_as_same, max_instance_size, max_series_size, delete_local_origin, dirty)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;129m@public_method\u001b[39m\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mappend\u001b[39m(\n\u001b[32m    212\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    218\u001b[39m     dirty: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    219\u001b[39m ):\n\u001b[32m    220\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Append a list of instances to the COD object.\u001b[39;00m\n\u001b[32m    221\u001b[39m \n\u001b[32m    222\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    228\u001b[39m \u001b[33;03m        dirty: bool - Must be `True` if the CODObject is \"dirty\" (i.e. `lock=False`).\u001b[39;00m\n\u001b[32m    229\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m230\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcod_object\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[43m        \u001b[49m\u001b[43minstances\u001b[49m\u001b[43m=\u001b[49m\u001b[43minstances\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdelete_local_origin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdelete_local_origin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtreat_metadata_diffs_as_same\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtreat_metadata_diffs_as_same\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_instance_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_instance_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_series_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_series_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/cloud_optimized_dicom/cloud_optimized_dicom/append.py:84\u001b[39m, in \u001b[36mappend\u001b[39m\u001b[34m(cod_object, instances, delete_local_origin, treat_metadata_diffs_as_same, max_instance_size, max_series_size)\u001b[39m\n\u001b[32m     82\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m append_result\n\u001b[32m     83\u001b[39m \u001b[38;5;66;03m# handle new\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m append_result = \u001b[43m_handle_new\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcod_object\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_change\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnew\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mappend_result\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     85\u001b[39m metrics.TAR_SUCCESS_COUNTER.inc()\n\u001b[32m     86\u001b[39m metrics.TAR_BYTES_PROCESSED.inc(os.path.getsize(cod_object.tar_file_path))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/cloud_optimized_dicom/cloud_optimized_dicom/append.py:391\u001b[39m, in \u001b[36m_handle_new\u001b[39m\u001b[34m(cod_object, new_state_changes, append_result)\u001b[39m\n\u001b[32m    381\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_handle_new\u001b[39m(\n\u001b[32m    382\u001b[39m     cod_object: \u001b[33m\"\u001b[39m\u001b[33mCODObject\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    383\u001b[39m     new_state_changes: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mtuple\u001b[39m[Instance, Optional[SeriesMetadata], Optional[\u001b[38;5;28mstr\u001b[39m]]],\n\u001b[32m    384\u001b[39m     append_result: AppendResult,\n\u001b[32m    385\u001b[39m ) -> AppendResult:\n\u001b[32m    386\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    387\u001b[39m \u001b[33;03m    Create/append to tar & upload; add to series metadata & upload.\u001b[39;00m\n\u001b[32m    388\u001b[39m \u001b[33;03m    Returns:\u001b[39;00m\n\u001b[32m    389\u001b[39m \u001b[33;03m        updated_append_result\u001b[39;00m\n\u001b[32m    390\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m391\u001b[39m     instances_added_to_tar = \u001b[43m_handle_create_tar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcod_object\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_state_changes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    392\u001b[39m     _handle_create_metadata(cod_object, instances_added_to_tar)\n\u001b[32m    393\u001b[39m     \u001b[38;5;66;03m# update append result\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/cloud_optimized_dicom/cloud_optimized_dicom/append.py:415\u001b[39m, in \u001b[36m_handle_create_tar\u001b[39m\u001b[34m(cod_object, new_state_changes)\u001b[39m\n\u001b[32m    412\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(cod_object._metadata.instances) > \u001b[32m0\u001b[39m:\n\u001b[32m    413\u001b[39m     cod_object.pull_tar(dirty=\u001b[38;5;129;01mnot\u001b[39;00m cod_object.lock)\n\u001b[32m--> \u001b[39m\u001b[32m415\u001b[39m instances_added_to_tar = \u001b[43m_create_or_append_tar\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcod_object\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mnew\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnew\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnew_state_changes\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    417\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    418\u001b[39m _create_sqlite_index(cod_object)\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m instances_added_to_tar\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/cloud_optimized_dicom/cloud_optimized_dicom/append.py:447\u001b[39m, in \u001b[36m_create_or_append_tar\u001b[39m\u001b[34m(cod_object, instances_to_add)\u001b[39m\n\u001b[32m    445\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(instances_added_to_tar) == \u001b[32m0\u001b[39m:\n\u001b[32m    446\u001b[39m     uri_str = \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.join([instance.dicom_uri \u001b[38;5;28;01mfor\u001b[39;00m instance \u001b[38;5;129;01min\u001b[39;00m instances_to_add])\n\u001b[32m--> \u001b[39m\u001b[32m447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGRADIENT_STATE_LOGS:FAILED_TO_TAR_ALL_INSTANCES:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00muri_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    448\u001b[39m logger.info(\n\u001b[32m    449\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGRADIENT_STATE_LOGS:POPULATED_TAR:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcod_object.tar_file_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos.path.getsize(cod_object.tar_file_path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m bytes)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    450\u001b[39m )\n\u001b[32m    451\u001b[39m \u001b[38;5;66;03m# tar has been altered, so it is no longer in sync with the datastore\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: GRADIENT_STATE_LOGS:FAILED_TO_TAR_ALL_INSTANCES:/var/folders/c2/zbssspdd0d95m1kv1c2z1tf80000gn/T/tmpu4ust4fw_1.2.826.0.1.3680043.8.498.53683297893086086544068651189614355506/1.2.826.0.1.3680043.8.498.53683297893086086544068651189614355506.tar://instances/1.2.826.0.1.3680043.8.498.51559928123146446551440195325528927455.dcm\n/var/folders/c2/zbssspdd0d95m1kv1c2z1tf80000gn/T/tmpu4ust4fw_1.2.826.0.1.3680043.8.498.53683297893086086544068651189614355506/1.2.826.0.1.3680043.8.498.53683297893086086544068651189614355506.tar://instances/1.2.826.0.1.3680043.8.498.25686983467200677455391333207792083612.dcm"
     ]
    }
   ],
   "source": [
    "def example_hash_function(uid: str) -> str:\n",
    "    \"\"\"\n",
    "    Example hash function that adds 1 to the last part of the uid (i.e 1.2.3.4 becomes 1.2.3.5)\n",
    "    \"\"\"\n",
    "    split_uid = uid.split(\".\")\n",
    "    last_part = split_uid[-1]\n",
    "    new_last_part = str(int(last_part) + 1)\n",
    "    split_uid[-1] = new_last_part\n",
    "    return \".\".join(split_uid)\n",
    "\n",
    "with CODObject(datastore_path=datastore_path, \n",
    "               client=client, \n",
    "               study_uid=instance_a.study_uid(), \n",
    "               series_uid=instance_a.series_uid(), \n",
    "               lock=False) as orig_cod:\n",
    "    hashed_study_uid = example_hash_function(orig_cod.study_uid)\n",
    "    hashed_series_uid = example_hash_function(orig_cod.series_uid)\n",
    "    orig_cod.pull_tar(dirty=True)\n",
    "    # get all the instances from the original COD\n",
    "    instances = [i for i in orig_cod.get_metadata(dirty=True).instances.values()]\n",
    "    # provide the instances with the function they should use to hash their UIDs\n",
    "    for i in instances:\n",
    "        i.uid_hash_func = example_hash_function\n",
    "    with CODObject(datastore_path=deid_datastore_path, \n",
    "                   client=client, \n",
    "                   study_uid=hashed_study_uid, \n",
    "                   series_uid=hashed_series_uid,\n",
    "                   hashed_uids=True,\n",
    "                   lock=False) as deid_cod:\n",
    "        # TODO: this doesnt work yet - need to extract the instances from the original tar\n",
    "        deid_cod.append(instances=instances, dirty=True)\n",
    "        \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
